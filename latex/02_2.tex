\section{Các thành phần chính của hệ thống RAG}

Hệ thống RAG được xây dựng dựa trên bốn khối chức năng kết hợp với nhau để tạo ra một quy trình xử lý thông tin hoàn chỉnh, bao gồm: (1) \emph{Xử lý tài liệu}, (2) \emph{Cơ sở dữ liệu vector}, (3) \emph{Cơ chế truy xuất}, và (4) \emph{Sinh câu trả lời}. Các thành phần này giúp hệ thống có khả năng xử lý các câu hỏi phức tạp và đưa ra câu trả lời chính xác dựa trên dữ liệu cụ thể. Mỗi thành phần đều có thể được tối ưu hóa và cải tiến độc lập, tạo ra tính linh hoạt cao trong việc nâng cấp và bảo trì hệ thống theo thời gian.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.99\linewidth]{Figures/02.1_rag-pipeline2.png}
    \caption{Các thành phần của hệ thống RAG}
    \label{fig:rag-full}
\end{figure}

\subsection{Xử lý tài liệu}

{Xử lý tài liệu} \emph{(Document processing)} đóng vai trò là cổng vào của toàn bộ hệ thống, chịu trách nhiệm chuyển đổi các định dạng tài liệu thô từ nhiều nguồn thành dữ liệu có cấu trúc. Thành phần này không chỉ đơn thuần là trích xuất văn bản từ PDF hay Word, mà còn bao gồm các kỹ thuật tinh vi như \emph{nhận dạng ký tự quang học} (OCR) đối với tài liệu scan, xử lý cấu trúc bảng phức tạp trong Excel và làm sạch nội dung web từ HTML. Quá trình này cần đảm bảo duy trì cấu trúc và ngữ cảnh của tài liệu gốc, đồng thời loại bỏ các thành phần nhiễu không mang tính thông tin như header, footer hoặc menu điều hướng.

Sau khi thu được văn bản đã làm sạch, hệ thống thực hiện \emph{phân đoạn văn bản} để chia nhỏ tài liệu thành những đoạn \emph{(chunk)} có kích thước phù hợp. Việc phân đoạn không chỉ đơn giản là cắt theo độ dài cố định, mà còn cần cân nhắc nhiều yếu tố. Kích thước đoạn phải đủ lớn để chứa đựng đầy đủ ngữ cảnh, nhưng cũng phải đủ nhỏ để mô hình embedding có thể xử lý hiệu quả. Đồng thời, việc tạo ra phần chồng lấn \emph{(overlap)} giữa các đoạn liền kề giúp hạn chế mất thông tin quan trọng tại ranh giới giữa các đoạn. Chiến lược phân đoạn tối ưu thường kết hợp nhiều tiêu chí như ranh giới câu, đoạn văn, hoặc thậm chí cả cấu trúc ngữ nghĩa của nội dung.

\subsection{Cơ sở dữ liệu vector}

{Cơ sở dữ liệu vector} \emph{(Vector database)} hay {Cơ sở tri thức} \emph{(Knowledge base)} là trái tim của hệ thống RAG, nơi lưu trữ và quản lý toàn bộ kiến thức đã được số hóa. Tại đây, mỗi đoạn văn bản được chuyển đổi thành một vector nhiều chiều thông qua các \emph{mô hình embedding}, tạo ra một biểu diễn số học chứa đựng ngữ nghĩa của đoạn văn bản đó, thuận tiện cho việc lưu trữ và tìm kiếm.

Mô hình embedding là một mô hình mạng nơ-ron được huấn luyện chuyên biệt để chuyển đổi văn bản thành các vector nhiều chiều, trong đó mỗi chiều đại diện cho một khía cạnh ngữ nghĩa khác nhau của văn bản. Mô hình này sử dụng kiến trúc Transformer để hiểu sâu sắc ngữ cảnh và quan hệ giữa các từ, cụm từ trong văn bản, từ đó tạo ra các vector có khả năng bảo toàn thông tin ngữ nghĩa gốc. Những mô hình embedding hiện đại thường có khả năng xử lý đa ngôn ngữ, cho phép hệ thống hoạt động hiệu quả với nhiều ngôn ngữ khác nhau, bao gồm cả tiếng Việt.

Cơ sở dữ liệu không chỉ đơn thuần lưu trữ các vector mà còn duy trì hệ thống chỉ mục \emph{(indexing)} phức tạp, cho phép tìm kiếm nhanh chóng. Thay vì phải so khớp tuần tự với toàn bộ tập vector, hệ thống sử dụng chỉ mục để định vị nhanh các vector gần nhất trong không gian nhiều chiều. Các cơ sở dữ liệu vector chuyên dụng thường tích hợp những thuật toán tìm kiếm tiên tiến như HNSW {(Hierarchical Navigable Small World)} hay IVF {(Inverted File)} nhằm tối ưu hóa quá trình tính toán độ tương đồng giữa các vector. Các thuật toán này hỗ trợ tìm kiếm lân cận xấp xỉ \emph{(approximate nearest neighbor search)}, giúp hệ thống xử lý hiệu quả trên quy mô hàng triệu phân đoạn trong khi vẫn đảm bảo thời gian phản hồi nhanh chóng.

\subsection{Cơ chế truy xuất}

{Cơ chế truy xuất} \emph{(Retrieval mechanism)} chịu trách nhiệm tìm ra những đoạn thông tin liên quan nhất đối với câu hỏi của người dùng. Quá trình này bắt đầu với việc mã hóa truy vấn bằng cùng loại mô hình embedding đã sử dụng để xây dựng cơ sở dữ liệu. Sau đó, hệ thống tiến hành tìm kiếm dựa trên độ tương đồng -- thường sử dụng {độ tương đồng cosine} \emph{(cosine similarity)} -- nhằm thu thập những nội dung phù hợp nhất. Độ tương đồng cosine giữa hai vector \(\mathbf{u}\) và \(\mathbf{v}\) được tính theo công thức:

\[
    \mathrm{similarity}(\mathbf{u},\mathbf{v})
    = \frac{\mathbf{u}\cdot\mathbf{v}}{\lVert \mathbf{u} \rVert \, \lVert \mathbf{v} \rVert}
\]

Dựa trên phép đo này, hệ thống trả về những phân đoạn có điểm tương đồng cao nhất so với truy vấn. Tuy nhiên, các kết quả thô từ bước tìm kiếm không phải lúc nào cũng chính xác tuyệt đối. Để nâng cao chất lượng, chúng có thể được lọc thêm bằng siêu dữ liệu \emph{(metadata)} -- chẳng hạn như thời gian, nguồn tài liệu hoặc thẻ chủ đề -- nhằm loại bỏ những đoạn không phù hợp về ngữ cảnh. Ngoài ra, các kết quả còn có thể được sắp xếp lại bằng một mô hình \emph{reranker} -- hoạt động ở cấp độ câu hoặc đoạn -- để tối ưu hóa thứ tự trả về theo mức độ liên quan thực sự đối với câu hỏi.

\subsection{Sinh câu trả lời}

{Sinh câu trả lời} \emph{(Answer generation)} là thành phần cuối cùng của hệ thống RAG, nơi LLM tạo ra câu trả lời hoàn chỉnh dựa trên ngữ cảnh đã được cung cấp. Truy vấn mở rộng, bao gồm truy vấn ban đầu của người dùng và các phân đoạn thông tin truy xuất từ cơ sở dữ liệu vector, được đưa vào cửa sổ ngữ cảnh của mô hình. Trong quá trình này, LLM không chỉ đơn thuần trích dẫn lại thông tin, mà còn thực hiện các bước quan trọng như diễn đạt lại, tổng hợp và liên kết dữ liệu từ nhiều nguồn để đưa ra câu trả lời tự nhiên và mạch lạc.

Để đảm bảo chất lượng, hệ thống có thể tích hợp thêm các kỹ thuật hậu xử lý như kiểm tra tính nhất quán, định dạng đầu ra theo yêu cầu, hoặc gắn kèm nguồn tham chiếu cho từng phần thông tin. Nhờ vậy, câu trả lời vừa bám sát dữ liệu thực tế, vừa duy trì được tính trôi chảy và dễ hiểu cho người dùng.


















