\section{Xây dựng và quản lý cơ sở dữ liệu vector}

\subsection{Tiền xử lý và phân đoạn văn bản}

Sau khi trích xuất được nội dung thô từ các nguồn tài liệu khác nhau, bước tiếp theo trong quy trình xây dựng hệ thống RAG là chuyển đổi văn bản dài thành các đoạn nhỏ phù hợp để phục vụ lưu trữ và tìm kiếm. Quá trình phân đoạn văn bản \emph{(text chunking)} đòi hỏi sự cân bằng: nếu đoạn quá ngắn, ngữ cảnh có thể bị rời rạc và khó hiểu đầy đủ ý nghĩa; ngược lại, nếu đoạn quá dài, mô hình embedding sẽ khó nắm bắt toàn bộ thông tin, từ đó làm giảm độ chính xác khi truy vấn.

Hệ thống sử dụng chiến lược phân đoạn dựa trên số lượng ký tự cố định với các tham số đã được tinh chỉnh: mỗi đoạn có kích thước tối đa (\texttt{chunk\_size}) \(8\,000\) ký tự và độ chồng lấn (\texttt{chunk\_overlap}) \(800\) ký tự giữa các đoạn liền kề. Ngưỡng \(8\,000\) ký tự được lựa chọn dựa trên khả năng xử lý của mô hình embedding, đồng thời đảm bảo đủ độ lớn để bao quát một hoặc vài ý chính hoàn chỉnh. Phần chồng lấn \(800\) ký tự đóng vai trò như một ``vùng đệm'', giúp hạn chế tình trạng cắt ngang thông tin quan trọng tại ranh giới giữa các đoạn, đặc biệt với những câu hoặc đoạn văn dài dễ bị chia tách một cách không tự nhiên.

Quá trình phân đoạn được thực hiện bởi lớp \texttt{RecursiveCharacterTextSplitter} trong thư viện LangChain -- một công cụ tinh vi cho phép tách văn bản theo mức độ ưu tiên của ký tự phân cách. Thay vì cắt cứng theo vị trí ký tự, bộ phân tách lần lượt ưu tiên các ranh giới tự nhiên của văn bản: đầu tiên là đoạn văn (\texttt{"\textbackslash n\textbackslash n"}), sau đó là câu (\texttt{"\textbackslash n"}), tiếp theo là từ (dấu cách), và cuối cùng mới đến ký tự đơn lẻ nếu không còn lựa chọn nào khác. Cách tiếp cận này giúp bảo toàn ngữ nghĩa và hạn chế tình trạng văn bản bị chia cắt thiếu tự nhiên.


Để cải thiện chất lượng của quá trình phân đoạn, hệ thống bổ sung các cơ chế kiểm soát tự động. Những đoạn quá ngắn (dưới ngưỡng tối thiểu, mặc định là 200 ký tự) hoặc chỉ chứa ký tự trống sẽ bị loại bỏ. Bên cạnh đó, mỗi đoạn văn bản sau khi phân tách đều được gắn kèm siêu dữ liệu quan trọng như tên file nguồn, số trang (đối với tài liệu PDF) và vị trí trong tài liệu gốc. Cách thiết kế này giúp đảm bảo khả năng truy xuất nguồn gốc thông tin trong các bước xử lý tiếp theo.

Trong môi trường đa người dùng, hệ thống tổ chức dữ liệu của mỗi tài khoản theo các thư mục riêng biệt và có hệ thống. Thư mục \texttt{docs/} lưu trữ các tài liệu gốc sau khi được tải lên hoặc thu thập từ web, duy trì định dạng và nội dung nguyên bản để phục vụ việc tham khảo hoặc xử lý lại khi cần. Thư mục \texttt{chunks/} chứa các phân đoạn văn bản thô đã qua xử lý, được lưu dưới dạng file văn bản thuần với tên file có cấu trúc \texttt{\{original\_filename\}\_chunk\_\{index\}.txt}. Việc lưu trữ các đoạn văn bản thô giúp dễ dàng phân tích chất lượng dữ liệu và điều chỉnh tham số phân đoạn trong tương lai. Cuối cùng, thư mục \texttt{vector\_db/} chứa cơ sở dữ liệu vector đã được mã hóa, sẽ được trình bày chi tiết trong phần tiếp theo.

\subsection{Vector embedding}

Từ các phân đoạn văn bản có cấu trúc thu được, hệ thống tiến hành chuyển đổi chúng thành dạng biểu diễn vector số thông qua quá trình nhúng \emph{(embedding)}. Đây là một trong những bước then chốt trong việc xây dựng khả năng tìm kiếm ngữ nghĩa của hệ thống RAG, bởi chất lượng của các vector nhúng ảnh hưởng trực tiếp đến độ chính xác khi truy xuất thông tin liên quan. Mục tiêu của quá trình này là nắm bắt và lưu trữ các mối quan hệ ngữ nghĩa phức tạp giữa từ ngữ, cụm từ và ý tưởng trong một không gian vector nhiều chiều.

Mô hình embedding được nghiên cứu và triển khai là \texttt{text-embedding-3-large} của OpenAI -- một trong những mô hình tiên tiến nhất hiện tại với khả năng xử lý đa ngôn ngữ mạnh mẽ. Mô hình này ánh xạ mỗi đoạn văn bản thành một vector nhúng có độ dài lên đến 3072 chiều, trong đó mỗi chiều biểu diễn một khía cạnh ngữ nghĩa khác nhau của văn bản. Việc lựa chọn \texttt{text-embedding-3-large} không chỉ dựa trên chất lượng embedding vượt trội (đặc biệt đối với nội dung tiếng Việt), mà còn nhờ tính ổn định, khả năng mở rộng của dịch vụ API, cùng sự tương thích tốt với các thư viện LangChain được tích hợp trong hệ thống.

So với các giải pháp embedding khác như \texttt{sentence-transformers} triển khai trực tiếp trên máy chủ, mô hình OpenAI mang lại ưu thế về chất lượng đầu ra và không yêu cầu tài nguyên GPU mạnh mẽ tại hạ tầng cục bộ. Tuy nhiên, điều này cũng đồng nghĩa với việc hệ thống phụ thuộc vào kết nối internet ổn định và phát sinh chi phí API cho mỗi lần gọi embedding. Trong chương trình hiện tại, khóa API được quản lý thông qua file cấu hình \texttt{.env}, đảm bảo tính bảo mật và tách biệt rõ ràng giữa mã nguồn và dữ liệu nhạy cảm.

Một thành phần quan trọng trong quá trình xây dựng cơ sở dữ liệu vector là cơ chế loại bỏ trùng lặp \emph{(deduplication)}, nhằm tránh lưu trữ nhiều lần những đoạn văn bản giống hệt nhau. Hệ thống sử dụng hàm băm SHA-256 để tạo ra dấu định danh duy nhất cho mỗi đoạn. Khi một phân đoạn mới được xử lý, hệ thống tính toán mã hash của nội dung và so sánh với các giá trị đã tồn tại; nếu trùng khớp, phân đoạn đó sẽ bị loại bỏ khỏi quy trình embedding. Cách tiếp cận này đặc biệt hữu ích khi làm việc với các tài liệu có nội dung chồng chéo (chẳng hạn các phiên bản khác nhau của cùng một báo cáo, hoặc khi người dùng vô tình tải lên cùng một file nhiều lần), giúp tiết kiệm thời gian xử lý, đồng thời giảm đáng kể chi phí API. Tuy nhiên, cần lưu ý rằng phương pháp băm chỉ phát hiện trùng lặp tuyệt đối về mặt ký tự, những đoạn có cùng ý nghĩa nhưng được diễn đạt khác nhau sẽ không bị coi là trùng lặp.


\subsection{Lưu trữ và lập chỉ mục}

Sau khi thu được các vector nhúng chất lượng cao, hệ thống cần một giải pháp lưu trữ chuyên dụng để quản lý chúng một cách hiệu quả và hỗ trợ truy xuất nhanh chóng. Khác với cơ sở dữ liệu quan hệ truyền thống vốn được thiết kế để lưu trữ dữ liệu dạng bảng, \emph{cơ sở dữ liệu vector} được tối ưu riêng cho việc tìm kiếm trong không gian nhiều chiều. Việc lựa chọn hệ quản trị cơ sở dữ liệu phù hợp không chỉ ảnh hưởng trực tiếp đến hiệu năng tìm kiếm mà còn quyết định khả năng mở rộng và độ ổn định của toàn bộ hệ thống RAG.

Trong dự án này, ChromaDB được lựa chọn làm giải pháp lưu trữ vector nhờ những ưu thế thực tiễn. ChromaDB được thiết kế dưới dạng một cơ sở dữ liệu nhúng \emph{(embedded database)}, có thể tích hợp trực tiếp trong ứng dụng Python mà không cần cài đặt và cấu hình máy chủ cơ sở dữ liệu riêng biệt, rất thuận tiện cho giai đoạn phát triển và vận hành ở quy mô vừa. Bên cạnh đó, ChromaDB hỗ trợ \emph{persistence} -- cơ chế lưu trữ dữ liệu bền vững trên đĩa cứng, giúp bảo toàn toàn bộ cơ sở dữ liệu vector ngay cả khi ứng dụng khởi động lại. Nhờ vậy, hệ thống vừa đảm bảo tính đơn giản trong triển khai, vừa duy trì được độ tin cậy khi vận hành lâu dài.


Trong hệ thống hiện tại, ChromaDB được cấu hình với khả năng hỗ trợ đa người dùng thông qua cơ chế tách biệt dữ liệu theo từng tài khoản. Cụ thể, mỗi người dùng được cấp phát một thư mục lưu trữ riêng theo mẫu \texttt{users/\{username\}/vector\_db/}, đảm bảo tính riêng tư và an toàn thông tin. Kiến trúc này cho phép mỗi người dùng xây dựng và quản lý cơ sở tri thức cá nhân một cách độc lập, không bị ảnh hưởng hay truy cập trái phép từ các tài khoản khác. Cơ chế cập nhật gia tăng \emph{(incremental update)} được triển khai thông qua việc theo dõi danh sách các file đã được xử lý trong \texttt{files.txt} đặt tại thư mục \texttt{vector\_db/} của từng người dùng. Khi một người dùng thêm tài liệu mới, hệ thống chỉ xử lý những file chưa tồn tại trong bộ nhớ đệm cá nhân của họ, tránh việc tính toán lại embedding cho toàn bộ cơ sở dữ liệu.

Quá trình lưu trữ được thực hiện thông qua hàm \texttt{get\_vectorstore\_user()} với tham số đầu vào là tên người dùng và danh sách file cần xử lý. Hàm này tự động khởi tạo các thư mục cần thiết cho người dùng, sau đó tạo mới hoặc nạp lại cơ sở dữ liệu vector từ thư mục lưu trữ tương ứng. Mỗi vector trong cơ sở dữ liệu được gắn với một định danh duy nhất cùng siêu dữ liệu kèm theo, bao gồm thông tin về nguồn gốc, đường dẫn file và các thuộc tính bổ sung như số trang đối với tài liệu PDF. Cấu trúc siêu dữ liệu được thiết kế linh hoạt, cho phép mở rộng thêm trường thông tin khi cần thiết mà không ảnh hưởng đến dữ liệu đã có sẵn.

ChromaDB áp dụng các thuật toán lập chỉ mục \emph{(indexing)} tiên tiến nhằm tối ưu hóa tốc độ tìm kiếm, trong đó tiêu biểu là HNSW. Về bản chất, HNSW xây dựng một đồ thị nhiều lớp, trong đó các vector được kết nối với nhau theo mối quan hệ lân cận. Khi thực hiện truy vấn, hệ thống bắt đầu từ lớp trên cùng có ít nút, sau đó điều hướng dần xuống các lớp dưới với mật độ kết nối lớn hơn để tìm ra các láng giềng gần nhất. Cơ chế này cho phép tìm kiếm lân cận xấp xỉ với độ phức tạp tiệm cận logarit, đạt được sự cân bằng giữa tốc độ và độ chính xác. Nhờ cấu trúc chỉ mục này, mỗi người dùng có thể duy trì hiệu suất truy vấn ổn định trong cơ sở dữ liệu cá nhân, ngay cả khi số lượng bản ghi tăng lên đến hàng triệu. Đây là yếu tố quan trọng để hệ thống có thể mở rộng mà không làm giảm trải nghiệm người dùng.


\subsection{Tìm kiếm và truy xuất}

Sau khi cơ sở dữ liệu vector được xây dựng hoàn chỉnh cho từng người dùng, bước tiếp theo là triển khai cơ chế tìm kiếm và truy xuất thông tin một cách hiệu quả. Đây được xem là ``trái tim'' của hệ thống RAG, bởi nó quyết định chất lượng câu trả lời cuối cùng thông qua khả năng xác định và lựa chọn những phân đoạn văn bản liên quan nhất đến truy vấn. Khác với phương pháp tìm kiếm từ khóa truyền thống, tìm kiếm dựa trên vector ngữ nghĩa có thể nắm bắt được ý nghĩa sâu sắc của câu hỏi và tìm ra thông tin phù hợp ngay cả khi không có sự trùng khớp về mặt từ ngữ.

Quá trình tìm kiếm bắt đầu với việc mã hóa truy vấn của người dùng thành vector nhúng bằng chính mô hình đã được sử dụng trong giai đoạn xây dựng cơ sở dữ liệu. Nhờ đó, vector truy vấn và các vector tài liệu cùng tồn tại trong một không gian ngữ nghĩa thống nhất, cho phép việc so sánh trở nên có ý nghĩa và chính xác hơn. Trong môi trường đa người dùng, mỗi truy vấn chỉ được thực hiện trên cơ sở dữ liệu cá nhân của người dùng hiện tại, đảm bảo tính riêng tư và bảo mật thông tin.

Hệ thống sử dụng \emph{độ tương đồng cosine} làm thước đo chính để xác định mức độ liên quan giữa vector truy vấn và các vector tài liệu. Độ tương đồng cosine có ưu điểm là không phụ thuộc vào độ lớn của vector mà chỉ xét đến góc tạo bởi chúng trong không gian đa chiều, từ đó phản ánh chính xác mối quan hệ ngữ nghĩa giữa các đoạn văn bản. Các kết quả tìm kiếm sẽ được sắp xếp theo thứ tự giảm dần của điểm tương đồng, với những phân đoạn có điểm cao nhất được ưu tiên lựa chọn để cung cấp cho mô hình sinh câu trả lời.

Để nâng cao chất lượng truy xuất, hệ thống kết hợp nhiều kỹ thuật lọc và tối ưu hóa. Số lượng kết quả trả về được giới hạn ở mức hợp lý (thường từ 5 đến 7 phân đoạn) để tránh làm tràn cửa sổ ngữ cảnh của mô hình sinh câu trả lời. Bên cạnh đó, các kết quả có điểm tương đồng dưới một ngưỡng tối thiểu (mặc định là \(0.7\)) sẽ bị loại bỏ, giúp loại trừ những đoạn văn ít liên quan và đảm bảo chỉ những thông tin thực sự có giá trị mới được đưa vào quá trình xây dựng phản hồi.

Siêu dữ liệu cũng đóng vai trò quan trọng trong việc cải thiện trải nghiệm người dùng và tính minh bạch của hệ thống. Mỗi phân đoạn được truy xuất đều kèm theo thông tin nguồn gốc như tên file, số trang và vị trí trong tài liệu gốc. Nhờ đó, người dùng có thể kiểm chứng độ tin cậy của câu trả lời cũng như tham khảo thêm ngữ cảnh mở rộng nếu cần thiết. Trong môi trường đa người dùng, siêu dữ liệu còn giúp đảm bảo rằng các trích dẫn và tham chiếu đều xuất phát từ kho tri thức của từng cá nhân, tránh nhầm lẫn hoặc rò rỉ thông tin giữa các tài khoản.